{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "mount_file_id": "1Rj7GKuU_qMOSEBWjQPqKWfXOqodZyY_l",
      "authorship_tag": "ABX9TyOnakAGOVRmeiULo2Jz8yfS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/1pawn0/persian-speech-to-text-via-whisper/blob/main/whisper_finetune_persian.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch_ver = torch.__version__.split('+')[0].split('.')\n",
        "if torch_ver[1] == '8':\n",
        "    print('Installing torchcodec 0.7')\n",
        "    %pip install torchcodec==0.7\n",
        "    import torchcodec\n",
        "elif torch_ver[1] == '9':\n",
        "    print('Installing torchcodec 0.8')\n",
        "    %pip install torchcodec==0.8\n",
        "    import torchcodec"
      ],
      "metadata": {
        "id": "TOU7JJJC5GBn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os, gc\n",
        "import httpx\n",
        "import torch, torchcodec\n",
        "import polars as pl\n",
        "from torch.utils.data import Dataset, TensorDataset, DataLoader\n",
        "from pathlib import Path\n",
        "from tqdm.notebook import tqdm\n",
        "from google.colab import userdata\n",
        "from transformers import (\n",
        "    BatchFeature,\n",
        "    WhisperConfig,\n",
        "    WhisperTokenizer,\n",
        "    WhisperFeatureExtractor,\n",
        "    WhisperForConditionalGeneration,\n",
        ")\n",
        "model_name = \"aictsharif/whisper-base-fa\""
      ],
      "metadata": {
        "id": "r3TCAsbIZ72B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Docs: https://huggingface.co/docs/transformers/main/en/model_doc/whisper\n",
        "\n",
        "https://huggingface.co/blog/fine-tune-whisper#fine-tuning-whisper-in-a-google-colab"
      ],
      "metadata": {
        "id": "J__x-3qs7DiK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = WhisperForConditionalGeneration.from_pretrained(model_name)\n",
        "fe = WhisperFeatureExtractor.from_pretrained(model_name)\n",
        "tok = WhisperTokenizer.from_pretrained(model_name, language=\"persian\", task=\"transcribe\")\n"
      ],
      "metadata": {
        "id": "GVOBKLTSz6KD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title download and extract the dataset\n",
        "\n",
        "base_url = \"https://datacollective.mozillafoundation.org/api\"\n",
        "api_key = userdata.get(\"MOZILLA_API_KEY\")\n",
        "client_id = userdata.get(\"MOZILLA_CLIENT_ID\")\n",
        "headers = {\"Authorization\": f\"Bearer {api_key}\", \"Content-Type\": \"application/json\"}\n",
        "res: dict = httpx.post(f\"{base_url}/datasets/cmflnuzw5j6l58skwzpc4ze0q/download\", headers=headers).json()\n",
        "filename = res[\"filename\"]\n",
        "download_url = res[\"downloadUrl\"]\n",
        "filesize = res[\"sizeBytes\"]\n",
        "content_type = res[\"contentType\"]\n",
        "expires_at = res[\"expiresAt\"]\n",
        "one_MB = int(2**20)\n",
        "!wget --header=\"Authorization: Bearer {api_key}\" -O \"{filename}\" \"{download_url}\"\n",
        "print(\"Be Patient!\")\n",
        "!tar -xzf \"{filename}\"\n",
        "print(\"The dataset has extracted.\")\n",
        "ds_path = Path('./cv-corpus-23.0-2025-09-05/fa')\n",
        "for fpath in ds_path.iterdir():\n",
        "    print(fpath)"
      ],
      "metadata": {
        "id": "DMTgmfXouIOZ",
        "collapsed": true,
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Run it if you already have the tarfile in your google drive\n",
        "!tar -xzf \"/content/drive/MyDrive/tmp/mcv-scripted-fa-v23.0.tar.gz\" -C \"/content/\""
      ],
      "metadata": {
        "id": "DeklG1lC7XsM",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title read tsv files using polars\n",
        "\n",
        "train = pl.read_csv(\n",
        "    source=\"cv-corpus-23.0-2025-09-05/fa/train.tsv\",\n",
        "    separator=\"\\t\",\n",
        "    use_pyarrow=True,\n",
        ").with_row_index()\n",
        "validated = pl.read_csv(\n",
        "    source=\"cv-corpus-23.0-2025-09-05/fa/validated.tsv\",\n",
        "    separator=\"\\t\",\n",
        "    use_pyarrow=True,\n",
        ")\n",
        "validated_sentences = pl.read_csv(\n",
        "    source=\"cv-corpus-23.0-2025-09-05/fa/validated.tsv\",\n",
        "    separator=\"\\t\",\n",
        "    use_pyarrow=True,\n",
        ")\n",
        "\n",
        "other = pl.read_csv(\n",
        "    source=\"cv-corpus-23.0-2025-09-05/fa/other.tsv\",\n",
        "    separator=\"\\t\",\n",
        "    use_pyarrow=True,\n",
        ")\n",
        "dev = pl.read_csv(\n",
        "    source=\"cv-corpus-23.0-2025-09-05/fa/dev.tsv\",\n",
        "    separator=\"\\t\",\n",
        "    use_pyarrow=True,\n",
        ")\n",
        "clip_durations = pl.read_csv(\n",
        "    source=\"cv-corpus-23.0-2025-09-05/fa/clip_durations.tsv\",\n",
        "    separator=\"\\t\",\n",
        "    use_pyarrow=True,\n",
        ")\n"
      ],
      "metadata": {
        "id": "I8qXFmSJO9aK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "audio_files_path = Path(\"./cv-corpus-23.0-2025-09-05/fa/clips\")\n",
        "waveforms = []\n",
        "batch_features = []\n",
        "sentences = []\n",
        "sample_rate_target = 16000\n",
        "max_duration = 30\n",
        "\n",
        "for i in tqdm(range(len(train))):\n",
        "    if i > 100:\n",
        "        break\n",
        "    fpath = audio_files_path / train[\"path\"][i]\n",
        "    sentence = train[\"sentence\"][i]\n",
        "    input_ids = tok.__call__(\n",
        "        sentence,\n",
        "        return_tensors=\"pt\",\n",
        "        return_attention_mask=False,\n",
        "    ).input_ids\n",
        "    waveform, pts, duration, sample_rate = torchcodec.decoders.AudioDecoder(\n",
        "        source=fpath,\n",
        "        sample_rate=16000,\n",
        "        num_channels=1,\n",
        "    ).get_all_samples()\n",
        "\n",
        "    waveform_30sec = waveform.squeeze(0)[: sample_rate_target * max_duration]\n",
        "\n",
        "    features: BatchFeature = fe.__call__(\n",
        "        raw_speech=waveform_30sec,\n",
        "        return_tensors=\"pt\",\n",
        "        sampling_rate=16000,\n",
        "        do_normalize=True,\n",
        "        return_attention_mask=False,\n",
        "    )\n",
        "    batch_features.append(features.input_features)\n",
        "    waveforms.append(waveform_30sec)\n",
        "    sentences.append(input_ids)\n"
      ],
      "metadata": {
        "id": "SiLzLkiHboZ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "all_features = torch.cat(batch_features, dim=0)\n",
        "\n",
        "all_input_ids = pad_sequence([ids.squeeze(0) for ids in sentences], batch_first=True, padding_value=tok.pad_token_id)\n",
        "\n",
        "dataset = TensorDataset(all_features, all_input_ids)\n"
      ],
      "metadata": {
        "id": "jEsOSO8RfW53"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gc.collect()"
      ],
      "metadata": {
        "id": "J-x6gBHuPG8y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "e2_Vgn8JpnYS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}