{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "mount_file_id": "1Rj7GKuU_qMOSEBWjQPqKWfXOqodZyY_l",
      "authorship_tag": "ABX9TyNDEeDj38bb+EwOfRKhS7IO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/1pawn0/persian-speech-to-text-via-whisper/blob/main/whisper_finetune_persian.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch_ver = torch.__version__.split('+')[0].split('.')\n",
        "if torch_ver[1] == '8':\n",
        "    print('Installing torchcodec 0.7')\n",
        "    %pip install torchcodec==0.7\n",
        "    import torchcodec\n",
        "elif torch_ver[1] == '9':\n",
        "    print('Installing torchcodec 0.8')\n",
        "    %pip install torchcodec==0.8\n",
        "    import torchcodec"
      ],
      "metadata": {
        "id": "TOU7JJJC5GBn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os, gc\n",
        "import httpx\n",
        "import torch, torchcodec\n",
        "import polars as pl\n",
        "from torch.utils.data import Dataset, TensorDataset, DataLoader\n",
        "from pathlib import Path\n",
        "from tqdm.notebook import tqdm\n",
        "from google.colab import userdata\n",
        "from transformers import (\n",
        "    BatchFeature,\n",
        "    WhisperConfig,\n",
        "    WhisperTokenizer,\n",
        "    WhisperFeatureExtractor,\n",
        "    WhisperForConditionalGeneration,\n",
        ")\n",
        "model_name = \"aictsharif/whisper-base-fa\""
      ],
      "metadata": {
        "id": "r3TCAsbIZ72B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Docs: https://huggingface.co/docs/transformers/main/en/model_doc/whisper\n",
        "\n",
        "https://huggingface.co/blog/fine-tune-whisper#fine-tuning-whisper-in-a-google-colab"
      ],
      "metadata": {
        "id": "J__x-3qs7DiK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = WhisperForConditionalGeneration.from_pretrained(model_name)\n",
        "fe = WhisperFeatureExtractor.from_pretrained(model_name)\n",
        "tok = WhisperTokenizer.from_pretrained(model_name, language=\"persian\", task=\"transcribe\")\n"
      ],
      "metadata": {
        "id": "GVOBKLTSz6KD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title download and extract the dataset\n",
        "\n",
        "base_url = \"https://datacollective.mozillafoundation.org/api\"\n",
        "api_key = userdata.get(\"MOZILLA_API_KEY\")\n",
        "client_id = userdata.get(\"MOZILLA_CLIENT_ID\")\n",
        "headers = {\"Authorization\": f\"Bearer {api_key}\", \"Content-Type\": \"application/json\"}\n",
        "res: dict = httpx.post(f\"{base_url}/datasets/cmflnuzw5j6l58skwzpc4ze0q/download\", headers=headers).json()\n",
        "filename = res[\"filename\"]\n",
        "download_url = res[\"downloadUrl\"]\n",
        "filesize = res[\"sizeBytes\"]\n",
        "content_type = res[\"contentType\"]\n",
        "expires_at = res[\"expiresAt\"]\n",
        "one_MB = int(2**20)\n",
        "!wget --header=\"Authorization: Bearer {api_key}\" -O \"{filename}\" \"{download_url}\"\n",
        "print(\"Be Patient!\")\n",
        "!tar -xzf \"{filename}\"\n",
        "print(\"The dataset has extracted.\")\n",
        "ds_path = Path('./cv-corpus-23.0-2025-09-05/fa')\n",
        "for fpath in ds_path.iterdir():\n",
        "    print(fpath)"
      ],
      "metadata": {
        "id": "DMTgmfXouIOZ",
        "collapsed": true,
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Run it if you already have the tarfile in your google drive\n",
        "!tar -xzf \"/content/drive/MyDrive/tmp/mcv-scripted-fa-v23.0.tar.gz\" -C \"/content/\""
      ],
      "metadata": {
        "id": "DeklG1lC7XsM",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title read tsv files using polars\n",
        "\n",
        "train = pl.read_csv(\n",
        "    source=\"cv-corpus-23.0-2025-09-05/fa/train.tsv\",\n",
        "    separator=\"\\t\",\n",
        "    use_pyarrow=True,\n",
        ")\n",
        "validated = pl.read_csv(\n",
        "    source=\"cv-corpus-23.0-2025-09-05/fa/validated.tsv\",\n",
        "    separator=\"\\t\",\n",
        "    use_pyarrow=True,\n",
        ")\n",
        "validated_sentences = pl.read_csv(\n",
        "    source=\"cv-corpus-23.0-2025-09-05/fa/validated.tsv\",\n",
        "    separator=\"\\t\",\n",
        "    use_pyarrow=True,\n",
        ")\n",
        "\n",
        "other = pl.read_csv(\n",
        "    source=\"cv-corpus-23.0-2025-09-05/fa/other.tsv\",\n",
        "    separator=\"\\t\",\n",
        "    use_pyarrow=True,\n",
        ")\n",
        "dev = pl.read_csv(\n",
        "    source=\"cv-corpus-23.0-2025-09-05/fa/dev.tsv\",\n",
        "    separator=\"\\t\",\n",
        "    use_pyarrow=True,\n",
        ")\n",
        "clip_durations = pl.read_csv(\n",
        "    source=\"cv-corpus-23.0-2025-09-05/fa/clip_durations.tsv\",\n",
        "    separator=\"\\t\",\n",
        "    use_pyarrow=True,\n",
        ")\n",
        "\n",
        "# max_chars = train[\"sentence\"].str.len_chars().quantile(.99) # = 63\n",
        "train = train.filter(pl.col(\"sentence\").str.len_chars() < 64).with_row_index()\n",
        "\n",
        "train = (\n",
        "    train.join(clip_durations, left_on=\"path\", right_on=\"clip\", how=\"left\")\n",
        "    .with_columns(pl.col(\"duration[ms]\").truediv(1000).alias(\"duration\"))\n",
        "    .drop(\"duration[ms]\")\n",
        ")\n"
      ],
      "metadata": {
        "id": "I8qXFmSJO9aK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title find tokenized input_ids' max_length\n",
        "# # Tokenize all of the input sentences to find the highest number of input_ids length\n",
        "# target_labels = tok.__call__(\n",
        "#     train[\"sentence\"].to_list(),\n",
        "#     return_tensors=\"pt\",\n",
        "#     return_attention_mask=False,\n",
        "#     padding=True,\n",
        "#     truncation=True,\n",
        "# ).input_ids.squeeze(0)\n",
        "\n",
        "# print(target_labels.shape) # torch.Size([29547, 52]), therefore the max_length is `52`\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "0FVSrzg6QjP1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AudioDataset(Dataset):\n",
        "    def __init__(\n",
        "        self,\n",
        "        df: pl.DataFrame,\n",
        "        feature_extractor: WhisperFeatureExtractor,\n",
        "        tokenizer: WhisperTokenizer,\n",
        "        audio_files_dir: Path,\n",
        "        target_sample_rate: int = 16000,\n",
        "        max_duration: int = 30,\n",
        "    ):\n",
        "        self.df = df\n",
        "        self.fe = feature_extractor\n",
        "        self.tok = tokenizer\n",
        "        self.fdir = audio_files_dir\n",
        "        self.sr = target_sample_rate\n",
        "        self.duration = max_duration\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        waveform: torch.Tensor = (\n",
        "            torchcodec.decoders.AudioDecoder(\n",
        "                source=self.fdir / self.df[\"path\"][idx],\n",
        "                sample_rate=self.sr,\n",
        "                num_channels=1,\n",
        "            )\n",
        "            .get_all_samples()\n",
        "            .data.squeeze(0)[: self.sr * self.duration]\n",
        "        )\n",
        "\n",
        "        features: BatchFeature = self.fe.__call__(\n",
        "            raw_speech=waveform,\n",
        "            return_tensors=\"pt\",\n",
        "            sampling_rate=self.sr,\n",
        "            do_normalize=True,\n",
        "            return_attention_mask=False,\n",
        "        ).input_features.squeeze(0)\n",
        "\n",
        "        target_label: torch.Tensor = self.tok.__call__(\n",
        "            self.df[\"sentence\"][idx],\n",
        "            return_tensors=\"pt\",\n",
        "            return_attention_mask=False,\n",
        "            # precalculated_longest_input_ids_tensor_length = 52\n",
        "            max_length=52,\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "        ).input_ids.squeeze(0)\n",
        "\n",
        "        return features, target_label\n",
        "\n",
        "\n",
        "audio_files_path = Path(\"./cv-corpus-23.0-2025-09-05/fa/clips\")\n",
        "ds = AudioDataset(train, fe, tok, audio_files_path)\n",
        "loader = DataLoader(\n",
        "    ds,\n",
        "    batch_size=32,\n",
        "    shuffle=True,\n",
        "    num_workers=2,\n",
        "    pin_memory=True,\n",
        "    persistent_workers=True,\n",
        ")\n"
      ],
      "metadata": {
        "id": "I5eeNT5X2ydg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for Xb, yb in loader:\n",
        "    print(f\"Xb: {Xb.shape}\")\n",
        "    print(f\"yb: {yb.shape}\")\n",
        "    break"
      ],
      "metadata": {
        "id": "s6aXNSAo5gRo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}